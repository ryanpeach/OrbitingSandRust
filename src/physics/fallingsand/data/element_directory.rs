use hashbrown::{HashMap, HashSet};

use crate::physics::heat::components::ThermodynamicTemperature;
use crate::physics::orbits::components::Mass;
use crate::physics::util::clock::Clock;

use super::super::convolution::behaviors::ElementGridConvolutionNeighbors;

use super::super::convolution::neighbor_indexes::{
    BottomNeighborIdxs, ElementGridConvolutionNeighborIdxs, LeftRightNeighborIdxs, TopNeighborIdxs,
};
use super::super::elements::element::Element;
use super::super::mesh::coordinate_directory::CoordinateDir;
use super::super::util::functions::modulo;
use super::super::util::grid::Grid;
use super::super::util::image::RawImage;
use super::super::util::vectors::{ChunkIjkVector, IjkVector, JkVector};
use super::element_grid::ElementGrid;

use rayon::prelude::*;

/// The number of frames it takes to fully process the directory
const FRAMES_PER_FULL_PROCESS: usize = 9;

/// A struct of textures for use in rendering
/// These are options so you can take them out of the struct and use them elsewhere
pub struct Textures {
    /// The actual texture of the elements
    pub texture: Option<RawImage>,
    /// The texture of the heat
    pub heat_texture: Option<RawImage>,
}

/// Useful for indicating at compile time that an iterable should be ran in parallel
#[derive(Clone, Default)]
struct Parallel<T>(T);
/// Useful for indicating at compile time that an iterable should be ran in sequence
#[derive(Clone, Default)]
struct Sequential<T>(T);
/// Each "item" in this struct gets generated by the cooresponding
/// calculate_ith_*_targets function
/// These each need to be spread out into 9 sets, one for each frame
/// Each of these is ran in sequence relative to each other
/// Whether they are ran in sequence based on their hashsets is different for each name
/// and usually described in the corresponding functions documentation
#[derive(Clone)]
struct ProcessTargets {
    standard_convolution: [Parallel<HashSet<ChunkIjkVector>>; 9],
    has_single_bottom_neighbor: [Sequential<HashSet<ChunkIjkVector>>; 9],
    has_multi_bottom_neighbor: [Parallel<HashSet<ChunkIjkVector>>; 9],
}

/// This calculates the convolution targets you would get by standard iteration over
/// 3x3 convolution kernels. It excludes known edge cases, like the bottom of a layer where there is a reduction in radial chunks.
/// Run this over 0..9 frame_nb to get the targets for each frame
fn calculate_ith_standard_convolution_targets(
    coords: CoordinateDir,
    frame_nb: usize,
) -> Parallel<HashSet<ChunkIjkVector>> {
    let mut out = HashSet::new();

    // We are going to iterate up every j chunk ignoring the layer they are on, so we need the total number of them
    let j_size = coords.get_total_number_concentric_chunks();
    debug_assert!(
        j_size % 3 == 0,
        "Number of chunks in concentric circle dimension must be divisible by 3, but it is {}",
        j_size
    );

    // We are going to iterate 9 times in self.process_count
    // We will start one forward every 3 iterations in the j dim
    // We will start one forward every iteration in the k dim, looping every 3 iterations
    let start_j = (frame_nb / 3) % 3;
    let start_k = frame_nb % 3;

    // We need to step by 3 to prevent overlap. Think of a 3x3 convolution
    for j in (start_j..j_size).step_by(3) {
        // Get our layer shape
        let (layer_num, chunk_layer_concentric_circle) = coords
            .get_layer_and_chunk_num_from_absolute_concentric_chunk(j)
            .expect("We are iterating in a well defined range");
        let chunk_layer_radial_chunks = coords.get_layer_num_radial_chunks(layer_num);
        let prev_chunk_layer_radial_chunks = {
            if j == 0 {
                1usize
            } else {
                coords.get_layer_num_radial_chunks(layer_num - 1)
            }
        };
        debug_assert!(
            chunk_layer_radial_chunks == 1 || chunk_layer_radial_chunks % 3 == 0,
            "Chunk layer radial lines must be divisible by 3, but it is {}",
            chunk_layer_radial_chunks
        );

        // Skip chunks who have a neighboring bottom layer which has a reduction in radial chunks
        // as this causes convolution overlap
        if chunk_layer_concentric_circle == 0
            && prev_chunk_layer_radial_chunks < chunk_layer_radial_chunks
            || prev_chunk_layer_radial_chunks == 1
        {
            continue;
        }

        // Some layers just have one chunk, we need to only produce these values on a new k
        if chunk_layer_radial_chunks == 1 && (frame_nb % 3) != 0 {
            continue;
        }

        // We need to step by 3 to prevent overlap. Think of a 3x3 convolution
        for k in (start_k..chunk_layer_radial_chunks).step_by(3) {
            out.insert(ChunkIjkVector {
                i: layer_num,
                j: chunk_layer_concentric_circle,
                k,
            });
        }
    }
    Parallel(out)
}

/// This really only calculates the core now
/// TODO: Maybe consider removing this
fn calculate_ith_has_single_bottom_neighbor_targets(
    coords: CoordinateDir,
    frame_nb: usize,
) -> Sequential<HashSet<ChunkIjkVector>> {
    let mut out = HashSet::new();
    let i_size = coords.get_num_layers();
    // For this we actually only need 3 frames
    if frame_nb >= 3 {
        return Sequential(out);
    }
    let start_i = frame_nb % 3;
    // We need to step by 3 to prevent overlap. Think of a 3x3 convolution
    for layer_num in (start_i..i_size).step_by(3) {
        // Skip any layers whos previous layer doesn't only have one chunk
        let prev_chunk_layer_radial_chunks = {
            if layer_num == 0 {
                1usize // Include the bottom layer
            } else {
                coords.get_layer_num_radial_chunks(layer_num - 1)
            }
        };
        if prev_chunk_layer_radial_chunks != 1 {
            continue;
        }

        // Now add all the k's in this layer
        let chunk_layer_radial_chunks = coords.get_layer_num_radial_chunks(layer_num);
        for k in 0..chunk_layer_radial_chunks {
            out.insert(ChunkIjkVector {
                i: layer_num,
                j: 0,
                k,
            });
        }
    }

    Sequential(out)
}

/// This calculates the targets for the edge case where the bottom layer has a different number of radial chunks than this layer.
/// In this case we still need to maintain a j step of 3, but we need to
/// process all k's sequentially.
fn calculate_ith_has_different_k_bottom_neighbor_targets(
    coords: CoordinateDir,
    frame_nb: usize,
) -> Parallel<HashSet<ChunkIjkVector>> {
    let mut out = HashSet::new();
    let i_size = coords.get_num_layers();
    // The calculate_ith_has_single_bottom_neighbor_targets stops at the third frame
    // we are going to start at the 4th frame and go to the 9th frame
    if frame_nb < 3 {
        return Parallel(out);
    }
    let k_start = (frame_nb - 3) % 6;
    // We need to step by 3 to prevent overlap. Think of a 3x3 convolution
    // We don't need to step by 3 because this only happens after concentric layer splitting
    // and concentric layer splitting starts with 3rds
    // and we will always be on the bottom chunk of the layer
    for layer_num in 1..i_size {
        // Skip any layers whos previous layer doesn't only have one chunk
        let chunk_layer_radial_chunks = coords.get_layer_num_radial_chunks(layer_num);
        let prev_chunk_layer_radial_chunks = coords.get_layer_num_radial_chunks(layer_num - 1);
        if prev_chunk_layer_radial_chunks == 1
            || prev_chunk_layer_radial_chunks == chunk_layer_radial_chunks
        {
            continue;
        }

        // Now add all the k's in this layer but skip by 6 to prevent overlap
        let chunk_layer_radial_chunks = coords.get_layer_num_radial_chunks(layer_num);
        for k in (k_start..chunk_layer_radial_chunks).step_by(6) {
            out.insert(ChunkIjkVector {
                i: layer_num,
                j: 0,
                k,
            });
        }
    }

    Parallel(out)
}

/// Pre calculate all the chunk idx's we need to process each frame.
/// We pregenerate these so that we can test them and so that we don't waste time recalculating them
#[allow(clippy::needless_range_loop)]
fn pregen_process_targets(coords: &CoordinateDir) -> ProcessTargets {
    let mut standard_convolution: [Parallel<HashSet<ChunkIjkVector>>; 9] = Default::default();
    let mut has_single_bottom_neighbor: [Sequential<HashSet<ChunkIjkVector>>; 9] =
        Default::default();
    let mut has_multi_bottom_neighbor: [Parallel<HashSet<ChunkIjkVector>>; 9] = Default::default();
    for i in 0..9 {
        standard_convolution[i] = calculate_ith_standard_convolution_targets(coords.clone(), i);
        has_single_bottom_neighbor[i] =
            calculate_ith_has_single_bottom_neighbor_targets(coords.clone(), i);
        has_multi_bottom_neighbor[i] =
            calculate_ith_has_different_k_bottom_neighbor_targets(coords.clone(), i);
    }
    ProcessTargets {
        standard_convolution,
        has_single_bottom_neighbor,
        has_multi_bottom_neighbor,
    }
}

/* Main Struct */
/// An element grid directory is like a coordinate directory, but for element grids
/// It follow the same layer structure
/// There is a coordinate directory at the root, but also each ElementGrid has its own
/// copy of the chunk coordinates associated with it for convenience
pub struct ElementGridDir {
    coords: CoordinateDir,
    chunks: Vec<Grid<Option<ElementGrid>>>,
    process_targets: ProcessTargets,
    process_count: usize,
    total_mass: Mass,
    max_temp: ThermodynamicTemperature,
    min_temp: ThermodynamicTemperature,
}

impl ElementGridDir {
    pub fn new_empty(coords: CoordinateDir) -> Self {
        let mut chunks: Vec<Grid<Option<ElementGrid>>> =
            Vec::with_capacity(coords.get_num_layers());
        for i in 0..coords.get_num_layers() {
            let j_size = coords.get_layer_num_concentric_chunks(i);
            let k_size = coords.get_layer_num_radial_chunks(i);
            let mut layer = Grid::new_empty(k_size, j_size);
            for j in 0..j_size {
                for k in 0..k_size {
                    let element_grid =
                        ElementGrid::new_empty(coords.get_chunk_at_idx(ChunkIjkVector { i, j, k }));
                    layer.replace(JkVector { j, k }, Some(element_grid));
                }
            }
            chunks.push(layer);
        }
        let process_targets = pregen_process_targets(&coords);
        let (max_temp, min_temp) = Self::calc_max_min_temp(&mut chunks);
        Self {
            coords,
            process_targets,
            process_count: 0,
            total_mass: Self::calc_total_mass(&mut chunks),
            max_temp,
            min_temp,
            chunks,
        }
    }

    pub fn new_checkerboard(
        coords: CoordinateDir,
        fill0: &dyn Element,
        fill1: &dyn Element,
    ) -> Self {
        let mut chunks: Vec<Grid<Option<ElementGrid>>> =
            Vec::with_capacity(coords.get_num_layers());
        for i in 0..coords.get_num_layers() {
            let j_size = coords.get_layer_num_concentric_chunks(i);
            let k_size = coords.get_layer_num_radial_chunks(i);
            let mut layer = Grid::new_empty(k_size, j_size);
            for j in 0..j_size {
                for k in 0..k_size {
                    let fill: &dyn Element = if (j + k) % 2 == 0 { fill0 } else { fill1 };
                    let element_grid = ElementGrid::new_filled(
                        coords.get_chunk_at_idx(ChunkIjkVector { i, j, k }),
                        fill,
                    );
                    layer.replace(JkVector { j, k }, Some(element_grid));
                }
            }
            chunks.push(layer);
        }
        let process_targets = pregen_process_targets(&coords);
        let (max_temp, min_temp) = Self::calc_max_min_temp(&mut chunks);
        Self {
            coords,
            process_targets,
            process_count: 0,
            total_mass: Self::calc_total_mass(&mut chunks),
            max_temp,
            min_temp,
            chunks,
        }
    }

    #[cfg(test)]
    fn get_process_targets(&self) -> ProcessTargets {
        self.process_targets.clone()
    }

    // TODO: This needs testing
    fn get_chunk_top_neighbors(&self, coord: ChunkIjkVector) -> TopNeighborIdxs {
        let top_chunk_in_layer = self.coords.get_layer_num_concentric_chunks(coord.i) - 1;
        let top_layer = self.coords.get_num_layers() - 1;
        let radial_lines = |i: usize| self.coords.get_layer_num_radial_chunks(i);
        let k_isize = coord.k as isize;

        // A convenience function for making a vector and adding it to the out set
        let make_vector = |i: usize, j: usize, k: isize| -> ChunkIjkVector {
            ChunkIjkVector {
                i,
                j,
                k: modulo(k, radial_lines(i)),
            }
        };

        // Default neighbors (assuming you are in the middle of stuff, not on a layer boundary)
        let default_neighbors = TopNeighborIdxs::Normal {
            tl: make_vector(coord.i, coord.j + 1, k_isize + 1),
            t: make_vector(coord.i, coord.j + 1, k_isize),
            tr: make_vector(coord.i, coord.j + 1, k_isize - 1),
        };

        match (coord.i, coord.j) {
            (i, _) if i == top_layer => match coord.j {
                j if j == top_chunk_in_layer => TopNeighborIdxs::TopOfGrid,
                _ => default_neighbors,
            },
            (i, j) if j == top_chunk_in_layer && radial_lines(i) != radial_lines(i + 1) => {
                TopNeighborIdxs::LayerTransition {
                    tl: make_vector(i + 1, 0, k_isize * 2 + 2),
                    t1: make_vector(i + 1, 0, k_isize * 2 + 1),
                    t0: make_vector(i + 1, 0, k_isize * 2),
                    tr: make_vector(i + 1, 0, k_isize * 2 - 1),
                }
            }
            (i, j) if j == top_chunk_in_layer && radial_lines(i) == radial_lines(i + 1) => {
                TopNeighborIdxs::Normal {
                    tl: make_vector(i + 1, 0, k_isize + 1),
                    t: make_vector(i + 1, 0, k_isize),
                    tr: make_vector(i + 1, 0, k_isize - 1),
                }
            }
            _ => default_neighbors,
        }
    }

    // TODO: This needs testing
    fn get_chunk_left_right_neighbors(&self, coord: ChunkIjkVector) -> LeftRightNeighborIdxs {
        let num_radial_chunks = self.coords.get_layer_num_radial_chunks(coord.i);
        debug_assert!(
            num_radial_chunks > 0,
            "Number of radial chunks must be greater than 0"
        );
        let left = ChunkIjkVector {
            i: coord.i,
            j: coord.j,
            k: modulo(coord.k as isize + 1, num_radial_chunks),
        };
        debug_assert_ne!(left, coord);
        let right = ChunkIjkVector {
            i: coord.i,
            j: coord.j,
            k: modulo(coord.k as isize - 1, num_radial_chunks),
        };
        debug_assert_ne!(right, coord);
        debug_assert_ne!(left, right);
        LeftRightNeighborIdxs::LR { l: left, r: right }
    }

    // TODO: This needs testing
    fn get_chunk_bottom_neighbors(&self, coord: ChunkIjkVector) -> BottomNeighborIdxs {
        let bottom_chunk_in_layer = 0usize;
        let bottom_layer = 0usize;
        let radial_chunks = |i: usize| self.coords.get_layer_num_radial_chunks(i);
        let top_chunk_in_prev_layer =
            |i: usize| self.coords.get_layer_num_concentric_chunks(i - 1) - 1;
        let k_isize = coord.k as isize;

        let make_vector = |i: usize, j: usize, k: isize| -> ChunkIjkVector {
            ChunkIjkVector {
                i,
                j,
                k: modulo(k, radial_chunks(i)),
            }
        };

        match (coord.i, coord.j, coord.k) {
            (i, j, _) if i == bottom_layer && j == bottom_chunk_in_layer => {
                BottomNeighborIdxs::BottomOfGrid
            }
            // If going down a layer but you are not at the bottom
            (i, j, k)
                if j == bottom_chunk_in_layer
                    && radial_chunks(i) != radial_chunks(i - 1)
                    && k % 2 == 0 =>
            {
                BottomNeighborIdxs::ChunkDoubling {
                    bl: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize / 2),
                    br: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize / 2 - 1),
                }
            }
            (i, j, k)
                if j == bottom_chunk_in_layer
                    && radial_chunks(i) != radial_chunks(i - 1)
                    && k % 2 == 1 =>
            {
                BottomNeighborIdxs::ChunkDoubling {
                    bl: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize / 2 + 1),
                    br: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize / 2),
                }
            }
            (i, j, _) if j == bottom_chunk_in_layer && radial_chunks(i) == radial_chunks(i - 1) => {
                BottomNeighborIdxs::Normal {
                    bl: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize + 1),
                    b: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize),
                    br: make_vector(coord.i - 1, top_chunk_in_prev_layer(i), k_isize - 1),
                }
            }
            _ => BottomNeighborIdxs::Normal {
                bl: make_vector(coord.i, coord.j - 1, k_isize + 1),
                b: make_vector(coord.i, coord.j - 1, k_isize),
                br: make_vector(coord.i, coord.j - 1, k_isize - 1),
            },
        }
    }

    fn get_chunk_neighbors(&self, coord: ChunkIjkVector) -> ElementGridConvolutionNeighborIdxs {
        let top = self.get_chunk_top_neighbors(coord);
        let left_right = self.get_chunk_left_right_neighbors(coord);
        let bottom = self.get_chunk_bottom_neighbors(coord);
        ElementGridConvolutionNeighborIdxs {
            top,
            left_right,
            bottom,
        }
    }

    pub fn package_coordinate_neighbors(
        &mut self,
        coord: ChunkIjkVector,
    ) -> Result<ElementGridConvolutionNeighbors, String> {
        let neighbors = self.get_chunk_neighbors(coord);
        let mut out = HashMap::new();
        for neighbor in neighbors.iter() {
            if let Some(chunk) = self.chunks[neighbor.i].replace(neighbor.to_jk_vector(), None) {
                out.insert(neighbor, chunk);
            } else {
                // In this case we need to unpackage the convolutions we have already packaged
                // and put the chunks back where they came from
                for (neighbor_idx, neighbor) in out.into_iter() {
                    let prev = self.chunks[neighbor_idx.i]
                        .replace(neighbor_idx.to_jk_vector(), Some(neighbor));
                    debug_assert!(prev.is_none(), "Somehow this chunk was already replaced.");
                }
                return Err(format!(
                    "Chunk {:?} is already borrowed by another convolution.",
                    neighbor
                ));
            }
        }
        Ok(ElementGridConvolutionNeighbors::new(neighbors, out))
    }

    // This takes ownership of the chunk and all its neighbors from the directory
    // and puts them into a target vector and a vector of convolutions
    // The taget vector and convolution vectors will then be iterated on in parallel
    fn package_convolutions(
        &mut self,
        target_chunk_coords: HashSet<ChunkIjkVector>,
    ) -> Result<(Vec<ElementGridConvolutionNeighbors>, Vec<ElementGrid>), Vec<ChunkIjkVector>> {
        let mut convolutions = Vec::new();
        let mut target_chunks = Vec::new();
        let mut failed_coords = Vec::new();

        for coord in &target_chunk_coords {
            let conv = self.package_coordinate_neighbors(*coord);
            let chunk = self.chunks[coord.i].replace(coord.to_jk_vector(), None);
            match (conv, chunk) {
                (Ok(conv), Some(chunk)) => {
                    convolutions.push(conv);
                    target_chunks.push(chunk);
                }
                _ => {
                    failed_coords.push(*coord);
                }
            }
        }
        if !failed_coords.is_empty() {
            self.unpackage_convolutions(convolutions, target_chunks);
            Err(failed_coords)
        } else {
            Ok((convolutions, target_chunks))
        }
    }

    /// The reverse of the package_convolutions function
    /// Puts the chunks back into the directory exactly where they were taken from
    /// This is easy because all elementgrids contain a coordinate
    fn unpackage_convolution(
        &mut self,
        mut target: ElementGrid,
        conv: ElementGridConvolutionNeighbors,
    ) {
        target
            .set_already_processed_deduplicated(true)
            .expect("should not have already been set");
        {
            let target_idx = target.get_chunk_coords().get_chunk_idx();
            let prev = self.chunks[target_idx.i].replace(target_idx.to_jk_vector(), Some(target));
            debug_assert!(prev.is_none(), "Somehow this chunk was already replaced.");
        }
        for (neighbor_idx, neighbor) in conv.into_iter() {
            let prev =
                self.chunks[neighbor_idx.i].replace(neighbor_idx.to_jk_vector(), Some(neighbor));
            debug_assert!(prev.is_none(), "Somehow this chunk was already replaced.");
        }
    }

    /// Unpackages more than one convolution at a time
    fn unpackage_convolutions(
        &mut self,
        convolutions: Vec<ElementGridConvolutionNeighbors>,
        target_chunks: Vec<ElementGrid>,
    ) {
        for (target_chunk, this_conv) in target_chunks.into_iter().zip(convolutions.into_iter()) {
            self.unpackage_convolution(target_chunk, this_conv);
        }
    }

    /// Using the already_processed flag, get all the chunks that have not been processed yet
    fn get_unprocessed_chunk_idxs(&self) -> Vec<ChunkIjkVector> {
        let mut out = Vec::new();
        for i in 0..self.coords.get_num_layers() {
            let j_size = self.coords.get_layer_num_concentric_chunks(i);
            let k_size = self.coords.get_layer_num_radial_chunks(i);
            for j in 0..j_size {
                for k in 0..k_size {
                    let coord = ChunkIjkVector { i, j, k };
                    if !self.get_chunk_by_chunk_ijk(coord).get_already_processed() {
                        out.push(coord);
                    }
                }
            }
        }
        out
    }

    /// Sets the already_processed flag to false for all chunks
    fn unlock_all_chunks(&mut self) {
        for i in 0..self.coords.get_num_layers() {
            let j_size = self.coords.get_layer_num_concentric_chunks(i);
            let k_size = self.coords.get_layer_num_radial_chunks(i);
            for j in 0..j_size {
                for k in 0..k_size {
                    let coord = ChunkIjkVector { i, j, k };
                    // Doesn't even matter if this fails
                    self.get_chunk_by_chunk_ijk_mut(coord)
                        .set_already_processed(false);
                }
            }
        }
    }

    /// Do one iteration of processing on the grid
    /// There are four passes in total, each call does one pass
    /// The passes ensure that no two adjacent elementgrids are processed at the same time
    /// This is important because elementgrids can effect one another at a maximum range of
    /// the size of one elementgrid.
    pub fn process(&mut self, current_time: Clock) {
        self.process_parallel(
            self.process_targets.standard_convolution[self.process_count % 9].clone(),
            current_time,
        );
        self.process_sequence(
            self.process_targets.has_single_bottom_neighbor[self.process_count % 9].clone(),
            current_time,
        );
        self.process_parallel(
            self.process_targets.has_multi_bottom_neighbor[self.process_count % 9].clone(),
            current_time,
        );
        self.process_count += 1;

        // Check for errors and unlock all chunks every 9 iterations
        if self.process_count % FRAMES_PER_FULL_PROCESS == 0 {
            debug_assert_eq!(
                self.get_unprocessed_chunk_idxs().len(),
                0,
                "After 9 iterations not all chunks are processed. Missing {:?}",
                self.get_unprocessed_chunk_idxs()
            );
            self.unlock_all_chunks();
            self.recalculate_everything();
        }
    }

    /// Recalculates all the saved values
    pub fn recalculate_everything(&mut self) {
        self.recalculate_max_min_temp();
        self.recalculate_total_mass();
    }

    /// Run process FRAMES_PER_FULL_PROCESS times
    pub fn process_full(&mut self, current_time: Clock) {
        for _ in 0..FRAMES_PER_FULL_PROCESS {
            self.process(current_time);
        }
    }

    /// Process a single chunk and its neighbors, mostly used for unit testing
    /// Also single threaded so should be good for debugging and tracing
    pub fn process_single_chunk(&mut self, current_time: Clock, coord: ChunkIjkVector) {
        let mut conv = self
            .package_coordinate_neighbors(coord)
            .expect("In runtime, this should never fail.");
        let mut chunk = self.chunks[coord.i]
            .replace(coord.to_jk_vector(), None)
            .expect("Should not have been replaced already.");
        chunk.process(self.get_coordinate_dir(), &mut conv, current_time);
        // Unpackage the convolution
        self.unpackage_convolution(chunk, conv);
    }

    /// Gets the textures of the targets updated in the last call to process
    pub fn get_updated_target_textures(&self) -> HashMap<ChunkIjkVector, Textures> {
        // You should call this function only AFTER calling process
        let process_count = self.process_count - 1;
        let targets1 = self.process_targets.standard_convolution[process_count % 9].clone();
        let targets2 = self.process_targets.has_single_bottom_neighbor[process_count % 9].clone();
        let targets3 = self.process_targets.has_multi_bottom_neighbor[process_count % 9].clone();
        let all_targets: Vec<ChunkIjkVector> = targets1
            .0
            .into_iter()
            .chain(targets2.0)
            .chain(targets3.0)
            .collect();
        let (max_temp, min_temp) = self.get_max_min_temp();
        all_targets
            .into_par_iter()
            .map(|target| {
                let chunk = self.get_chunk_by_chunk_ijk(target);
                (
                    target,
                    Textures {
                        texture: Some(chunk.get_texture()),
                        heat_texture: Some(chunk.get_heat_texture(max_temp, min_temp)),
                    },
                )
            })
            .collect()
    }

    fn process_sequence(
        &mut self,
        targets: Sequential<HashSet<ChunkIjkVector>>,
        current_time: Clock,
    ) {
        for target in targets.0 {
            let mut conv = self
                .package_coordinate_neighbors(target)
                .expect("In runtime, this should never fail.");
            let mut chunk = self.chunks[target.i]
                .replace(target.to_jk_vector(), None)
                .expect("Should not have been replaced already.");
            chunk.process(self.get_coordinate_dir(), &mut conv, current_time);
            // Unpackage the convolution
            self.unpackage_convolution(chunk, conv);
        }
    }
    fn process_parallel(
        &mut self,
        targets: Parallel<HashSet<ChunkIjkVector>>,
        current_time: Clock,
    ) {
        let (mut convolutions, mut target_chunks) = self
            .package_convolutions(targets.0)
            .expect("In runtime, this should never fail.");
        convolutions
            .par_iter_mut()
            .zip(target_chunks.par_iter_mut())
            .for_each(|(convolution, target_chunk)| {
                target_chunk.process(self.get_coordinate_dir(), convolution, current_time);
            });
        self.unpackage_convolutions(convolutions, target_chunks);
    }

    /// Get the number of chunks from the coordinate directory
    pub fn get_num_chunks(&self) -> usize {
        self.coords.get_num_chunks()
    }
    pub fn get_total_num_cells(&self) -> usize {
        let mut out = 0;
        for i in 0..self.coords.get_num_layers() {
            let j_size = self.coords.get_layer_num_concentric_chunks(i);
            let k_size = self.coords.get_layer_num_radial_chunks(i);
            for j in 0..j_size {
                for k in 0..k_size {
                    let coord = ChunkIjkVector { i, j, k };
                    out += self
                        .get_chunk_by_chunk_ijk(coord)
                        .get_chunk_coords()
                        .total_size();
                }
            }
        }
        out
    }

    /// Get the total mass of the directory
    pub fn get_total_mass(&self) -> Mass {
        self.total_mass
    }

    /// Recalculate the total mass of the directory
    fn recalculate_total_mass(&mut self) {
        self.total_mass = Self::calc_total_mass(&mut self.chunks);
    }

    /// Calculate the maximum temperature in the directory
    pub fn calc_total_mass(chunks: &mut Vec<Grid<Option<ElementGrid>>>) -> Mass {
        let mut out = Mass(0.0);
        for layer in chunks {
            for chunk in layer.into_iter().flatten() {
                chunk.recalculate_total_mass();
                out += chunk.get_total_mass();
            }
        }
        out
    }

    /// Get the maximum temperature in the directory
    pub fn get_max_min_temp(&self) -> (ThermodynamicTemperature, ThermodynamicTemperature) {
        (self.max_temp, self.min_temp)
    }

    /// Recalculate the maximum temperature in the directory
    fn recalculate_max_min_temp(&mut self) {
        (self.max_temp, self.min_temp) = Self::calc_max_min_temp(&mut self.chunks);
    }

    /// Calculate the maximum temperature in the directory
    pub fn calc_max_min_temp(
        chunks: &mut Vec<Grid<Option<ElementGrid>>>,
    ) -> (ThermodynamicTemperature, ThermodynamicTemperature) {
        let mut max = ThermodynamicTemperature(0.0);
        let mut min = ThermodynamicTemperature(f32::INFINITY);
        for layer in chunks {
            for chunk in layer.into_iter().flatten() {
                chunk.recalculate_heat();
                let temp = chunk.get_temperature();
                if temp > max {
                    max = temp;
                }
                // Min temperature should be greater than 0
                if temp < min && temp > ThermodynamicTemperature(0.0) {
                    min = temp;
                }
            }
        }
        (max, min)
    }

    /// Gets the chunk at the given index
    /// Errors if it is currently borrowed
    pub fn get_chunk_by_chunk_ijk(&self, coord: ChunkIjkVector) -> &ElementGrid {
        self.chunks[coord.i]
            .get(coord.to_jk_vector())
            .as_ref()
            .unwrap()
    }
    /// Gets the chunk at the given index mutably
    /// Errors if it is currently borrowed
    pub fn get_chunk_by_chunk_ijk_mut(&mut self, coord: ChunkIjkVector) -> &mut ElementGrid {
        self.chunks[coord.i]
            .get_mut(coord.to_jk_vector())
            .as_mut()
            .unwrap()
    }

    #[allow(clippy::borrowed_box)]
    pub fn get_element(&self, coord: IjkVector) -> &Box<dyn Element> {
        let chunk_idx = self.get_coordinate_dir().cell_idx_to_chunk_idx(coord);
        let chunk = self.get_chunk_by_chunk_ijk(chunk_idx.0);
        chunk.get(chunk_idx.1)
    }

    pub fn set_element(
        &mut self,
        coord: IjkVector,
        element: Box<dyn Element>,
        current_time: Clock,
    ) {
        let chunk_idx = self.get_coordinate_dir().cell_idx_to_chunk_idx(coord);
        let chunk = self.get_chunk_by_chunk_ijk_mut(chunk_idx.0);
        chunk.set(chunk_idx.1, element, current_time);
    }

    pub fn get_coordinate_dir(&self) -> &CoordinateDir {
        &self.coords
    }
    pub fn len(&self) -> usize {
        self.chunks.len()
    }
    pub fn is_empty(&self) -> bool {
        self.chunks.is_empty()
    }

    /// Get all textures
    pub fn get_textures(&self) -> HashMap<ChunkIjkVector, Textures> {
        // Create a filter with all true
        let mut filter: Vec<Grid<bool>> = Vec::with_capacity(self.coords.get_num_layers());
        for i in 0..self.coords.get_num_layers() {
            let j_size = self.coords.get_layer_num_concentric_chunks(i);
            let k_size = self.coords.get_layer_num_radial_chunks(i);
            let layer = Grid::new_from_vec(k_size, j_size, vec![true; k_size * j_size]);
            filter.push(layer);
        }

        // Call the filtered version
        self.get_textures_filtered(&filter)
    }

    /// Where filter is true, get the textures
    fn get_textures_filtered(&self, filter: &[Grid<bool>]) -> HashMap<ChunkIjkVector, Textures> {
        let mut out = HashMap::new();
        let (max_temp, min_temp) = self.get_max_min_temp();
        for (i, item) in filter.iter().enumerate() {
            let j_size = self.coords.get_layer_num_concentric_chunks(i);
            let k_size = self.coords.get_layer_num_radial_chunks(i);
            for j in 0..j_size {
                for k in 0..k_size {
                    if !item.get(JkVector { j, k }) {
                        continue;
                    }
                    let coord = ChunkIjkVector { i, j, k };
                    let tex = self.get_chunk_by_chunk_ijk(coord).get_texture();
                    let heat_tex = self
                        .get_chunk_by_chunk_ijk(coord)
                        .get_heat_texture(max_temp, min_temp);
                    out.insert(
                        coord,
                        Textures {
                            texture: Some(tex),
                            heat_texture: Some(heat_tex),
                        },
                    );
                }
            }
        }
        out
    }
}

#[cfg(test)]
mod tests {
    use crate::physics::{self, fallingsand::mesh::coordinate_directory::CoordinateDirBuilder};

    use super::*;

    /// The default element grid directory for testing
    fn get_element_grid_dir() -> ElementGridDir {
        let coordinate_dir = CoordinateDirBuilder::new()
            .cell_radius(physics::heat::components::Length(1.0))
            .num_layers(9)
            .first_num_radial_lines(6)
            .second_num_concentric_circles(3)
            .max_concentric_circles_per_chunk(64)
            .max_radial_lines_per_chunk(64)
            .build();
        ElementGridDir::new_empty(coordinate_dir)
    }

    mod neighbors {

        use super::*;

        /// Going to verify the chunk grid sizes before we start testing, and so we can know if they change
        #[test]
        fn test_grid_sizes() {
            let element_grid_dir = get_element_grid_dir();
            assert_eq!(element_grid_dir.len(), 9);

            // Core
            assert_eq!(element_grid_dir.chunks[0].get_height(), 1);
            assert_eq!(element_grid_dir.chunks[0].get_width(), 3);

            // Layer 1
            assert_eq!(element_grid_dir.chunks[1].get_height(), 1);
            assert_eq!(element_grid_dir.chunks[1].get_width(), 3);

            // Layer 2
            assert_eq!(element_grid_dir.chunks[2].get_height(), 1);
            assert_eq!(element_grid_dir.chunks[2].get_width(), 3);

            // Layer 3
            assert_eq!(element_grid_dir.chunks[3].get_height(), 3);
            assert_eq!(element_grid_dir.chunks[3].get_width(), 3);

            // Layer 4
            assert_eq!(element_grid_dir.chunks[4].get_height(), 3);
            assert_eq!(element_grid_dir.chunks[4].get_width(), 6);

            // Layer 5
            assert_eq!(element_grid_dir.chunks[5].get_height(), 3);
            assert_eq!(element_grid_dir.chunks[5].get_width(), 12);

            // Layer 6
            assert_eq!(element_grid_dir.chunks[6].get_height(), 6);
            assert_eq!(element_grid_dir.chunks[6].get_width(), 24);

            // Layer 7
            assert_eq!(element_grid_dir.chunks[7].get_height(), 12);
            assert_eq!(element_grid_dir.chunks[7].get_width(), 48);

            // Layer 8
            assert_eq!(element_grid_dir.chunks[8].get_height(), 24);
            assert_eq!(element_grid_dir.chunks[8].get_width(), 96);
        }

        #[test]
        fn test_get_chunk_neighbors() {
            let element_grid_dir = get_element_grid_dir();

            // Core
            // Has no chunks below it
            {
                let coord = ChunkIjkVector { i: 0, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 5, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 0, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 0, j: 0, k: 2 }));
            }

            // Layer 1
            {
                let coord = ChunkIjkVector { i: 1, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 8, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 0, j: 0, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 0, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 0, j: 0, k: 2 }));
            }

            // Layer 2
            {
                let coord = ChunkIjkVector { i: 2, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 8, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 0, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 0, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 1, j: 0, k: 2 }));
            }

            // Layer 3
            {
                let coord = ChunkIjkVector { i: 3, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 8, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 1, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 1, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 1, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 0, k: 2 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 2, j: 0, k: 2 }));
            }

            // Layer 4
            // This is the first special one, because it is the first layer with fewer chunks below it
            {
                let coord = ChunkIjkVector { i: 4, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 7, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 1, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 1, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 1, k: 5 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 0, k: 5 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 2, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 3, j: 2, k: 2 }));
            }

            // Layer 5,
            {
                let coord = ChunkIjkVector { i: 5, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 7, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 2, k: 5 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 4, j: 2, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 0, k: 11 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 1, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 1, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 1, k: 11 }));
            }

            // Layer 6
            {
                let coord = ChunkIjkVector { i: 6, j: 0, k: 0 };
                let neighbors = element_grid_dir.get_chunk_neighbors(coord);
                assert_eq!(neighbors.iter().count(), 7, "{:?}", neighbors);
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 2, k: 11 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 5, j: 2, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 6, j: 0, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 6, j: 0, k: 23 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 6, j: 1, k: 0 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 6, j: 1, k: 1 }));
                assert!(neighbors.contains(&ChunkIjkVector { i: 6, j: 1, k: 23 }));
            }
        }
    }

    mod get_next_targets {
        use super::*;

        /// Going to verify the chunk grid sizes before we start testing, and so we can know if they change
        #[test]
        fn test_grid_sizes() {
            let element_grid_dir = get_element_grid_dir();
            assert_eq!(element_grid_dir.len(), 9);

            // Core
            assert_eq!(element_grid_dir.chunks[0].get_height(), 1);
            assert_eq!(element_grid_dir.chunks[0].get_width(), 3);

            // Layer 1
            assert_eq!(element_grid_dir.chunks[1].get_height(), 1);
            assert_eq!(element_grid_dir.chunks[1].get_width(), 3);

            // Layer 2
            assert_eq!(element_grid_dir.chunks[2].get_height(), 1);
            assert_eq!(element_grid_dir.chunks[2].get_width(), 3);

            // Layer 3
            assert_eq!(element_grid_dir.chunks[3].get_height(), 3);
            assert_eq!(element_grid_dir.chunks[3].get_width(), 3);

            // Layer 4
            assert_eq!(element_grid_dir.chunks[4].get_height(), 3);
            assert_eq!(element_grid_dir.chunks[4].get_width(), 6);

            // Layer 5
            assert_eq!(element_grid_dir.chunks[5].get_height(), 3);
            assert_eq!(element_grid_dir.chunks[5].get_width(), 12);

            // Layer 6
            assert_eq!(element_grid_dir.chunks[6].get_height(), 6);
            assert_eq!(element_grid_dir.chunks[6].get_width(), 24);

            // Layer 7
            assert_eq!(element_grid_dir.chunks[7].get_height(), 12);
            assert_eq!(element_grid_dir.chunks[7].get_width(), 48);

            // Layer 8
            assert_eq!(element_grid_dir.chunks[8].get_height(), 24);
            assert_eq!(element_grid_dir.chunks[8].get_width(), 96);
        }

        fn get_next_targets(this: &mut ElementGridDir) -> HashSet<ChunkIjkVector> {
            let out1 = this.process_targets.standard_convolution[this.process_count % 9].clone();
            let out2 =
                this.process_targets.has_single_bottom_neighbor[this.process_count % 9].clone();
            let out3 =
                this.process_targets.has_multi_bottom_neighbor[this.process_count % 9].clone();
            this.process_count += 1;
            out1.0.into_iter().chain(out2.0).chain(out3.0).collect()
        }

        /// Test that every chunk is targetted exactly once in 9 iterations
        #[test]
        fn test_get_next_targets_full_coverage() {
            let mut element_grid_dir = get_element_grid_dir();
            let mut all_targets = HashSet::new();
            for _ in 0..9 {
                let targets = get_next_targets(&mut element_grid_dir);
                all_targets.extend(targets);
            }
            // Just to display what is missing
            let mut full_coverage = HashSet::new();
            for i in 0..element_grid_dir.coords.get_num_layers() {
                let j_size = element_grid_dir.coords.get_layer_num_concentric_chunks(i);
                let k_size = element_grid_dir.coords.get_layer_num_radial_chunks(i);
                for j in 0..j_size {
                    for k in 0..k_size {
                        full_coverage.insert(ChunkIjkVector { i, j, k });
                    }
                }
            }
            assert_eq!(
                all_targets.len(),
                element_grid_dir.coords.get_num_chunks(),
                "{:?}",
                full_coverage.difference(&all_targets)
            );
        }

        /// Test that no chunk is targetted twice in 9 iterations
        #[test]
        fn test_get_next_targets_no_duplicates() {
            let mut element_grid_dir = get_element_grid_dir();
            let mut all_targets = HashSet::new();
            for process_count in 0..9 {
                let targets = get_next_targets(&mut element_grid_dir);
                for t in &targets {
                    assert!(
                        !all_targets.contains(t),
                        "process_count: {}, t: {:?}",
                        process_count,
                        t
                    );
                }
                all_targets.extend(targets);
            }
        }

        #[test]
        fn test_standard_convolution_packaging() {
            let mut element_grid_dir = get_element_grid_dir();
            let process_targets = element_grid_dir.get_process_targets();
            for frame_nb in 0..9 {
                let res = element_grid_dir
                    .package_convolutions(process_targets.standard_convolution[frame_nb].0.clone());
                match res {
                    Ok((convolutions, target_chunks)) => {
                        assert_eq!(convolutions.len(), target_chunks.len());
                        element_grid_dir.unpackage_convolutions(convolutions, target_chunks);
                    }
                    Err(e) => {
                        panic!(
                            "The following vectors for frame {} could not be packaged: {:?}",
                            frame_nb, e
                        );
                    }
                }
            }
        }

        #[test]
        fn test_has_multi_bottom_neighbor_packaging() {
            let mut element_grid_dir = get_element_grid_dir();
            let process_targets = element_grid_dir.get_process_targets();
            for frame_nb in 0..9 {
                let res = element_grid_dir.package_convolutions(
                    process_targets.has_multi_bottom_neighbor[frame_nb]
                        .0
                        .clone(),
                );
                match res {
                    Ok((convolutions, target_chunks)) => {
                        assert_eq!(convolutions.len(), target_chunks.len());
                        element_grid_dir.unpackage_convolutions(convolutions, target_chunks);
                    }
                    Err(e) => {
                        panic!(
                            "The following vectors for frame {} could not be packaged: {:?}",
                            frame_nb, e
                        );
                    }
                }
            }
        }

        /// Not really necessary since this is done in sequence but good to have a test anyway
        #[test]
        fn test_has_single_bottom_neighbor_packaging() {
            let mut element_grid_dir = get_element_grid_dir();
            let process_targets = element_grid_dir.get_process_targets();
            for frame_nb in 0..9 {
                for chunk_coord in process_targets.has_single_bottom_neighbor[frame_nb]
                    .0
                    .iter()
                {
                    let conv = element_grid_dir
                        .package_coordinate_neighbors(*chunk_coord)
                        .unwrap();
                    let chunk = element_grid_dir.chunks[chunk_coord.i]
                        .replace(chunk_coord.to_jk_vector(), None)
                        .unwrap();
                    element_grid_dir.unpackage_convolution(chunk, conv);
                }
            }
        }

        #[test]
        #[warn(unused_variables)]
        fn test_get_next_targets_manual_j_dim() {
            let mut element_grid_dir = get_element_grid_dir();
            let all_targets_1 = get_next_targets(&mut element_grid_dir);

            // For every j step by 3 we should
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 0, j: 0, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 3, j: 0, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 6, j: 3, k: 0 }));
            // assert!(all_targets_1.contains(&ChunkIjkVector { i: 7, j: 0, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 7, j: 3, k: 0 }));
            // assert!(all_targets_1.contains(&ChunkIjkVector { i: 8, j: 0, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 8, j: 3, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 8, j: 6, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 8, j: 9, k: 0 }));

            get_next_targets(&mut element_grid_dir);
            get_next_targets(&mut element_grid_dir);
            let all_targets_2 = get_next_targets(&mut element_grid_dir);

            // assert!(all_targets_2.contains(&ChunkIjkVector { i: 1, j: 0, k: 0 }));
            // assert!(all_targets_2.contains(&ChunkIjkVector { i: 4, j: 0, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 6, j: 1, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 7, j: 1, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 7, j: 4, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 8, j: 1, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 8, j: 4, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 8, j: 7, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 8, j: 10, k: 0 }));

            get_next_targets(&mut element_grid_dir);
            get_next_targets(&mut element_grid_dir);
            let all_targets_3 = get_next_targets(&mut element_grid_dir);

            // assert!(all_targets_3.contains(&ChunkIjkVector { i: 2, j: 0, k: 0 }));
            // assert!(all_targets_3.contains(&ChunkIjkVector { i: 5, j: 0, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 6, j: 2, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 7, j: 2, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 7, j: 5, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 8, j: 2, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 8, j: 5, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 8, j: 8, k: 0 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 8, j: 11, k: 0 }));
        }

        #[test]
        fn test_get_next_targets_manual_k_dim() {
            let mut element_grid_dir = get_element_grid_dir();
            let all_targets_1 = get_next_targets(&mut element_grid_dir);

            // Same as first test
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 0, j: 0, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 3, j: 0, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 6, j: 3, k: 0 }));
            assert!(all_targets_1.contains(&ChunkIjkVector { i: 6, j: 3, k: 3 }));

            let all_targets_2 = get_next_targets(&mut element_grid_dir);

            // Layers that only have one chunk should not repeat
            assert!(!all_targets_2.contains(&ChunkIjkVector { i: 0, j: 0, k: 0 }));
            assert!(!all_targets_2.contains(&ChunkIjkVector { i: 3, j: 0, k: 0 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 6, j: 3, k: 1 }));
            assert!(all_targets_2.contains(&ChunkIjkVector { i: 6, j: 3, k: 4 }));

            let all_targets_3 = get_next_targets(&mut element_grid_dir);

            assert!(all_targets_3.contains(&ChunkIjkVector { i: 6, j: 3, k: 2 }));
            assert!(all_targets_3.contains(&ChunkIjkVector { i: 6, j: 3, k: 5 }));
        }
    }
}
